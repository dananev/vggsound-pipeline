[project]
name = "vggsound-pipeline"
version = "0.1.0"
description = "Filter VGGSound for sound effects with ML-based classification"
requires-python = ">=3.12,<3.13"
dependencies = [
    "transformers>=4.48",
    "typer>=0.9",
    "pydantic>=2.0",
    "pydantic-settings>=2.0",
    "orjson>=3.9",
    "tqdm>=4.65",
    "ffmpeg-python>=0.2",
    "decord>=0.6",
    "soundfile>=0.12",
    "peft>=0.10",
    "safetensors>=0.4",
    "pillow>=10.0",
]

[project.optional-dependencies]
dev = ["ruff", "pytest", "pytest-cov"]
cpu = [
    "torch>=2.6",
    "torchaudio>=2.6",
    "torchcodec>=0.2",
    "accelerate>=0.27",
]
cuda = [
    "torch==2.9.0",
    "torchaudio==2.9.0",
    "torchcodec==0.9",
    "accelerate>=0.27",
]
cuda-fast = [
    "torch==2.9.0",
    "torchaudio==2.9.0",
    "torchcodec==0.9",
    "accelerate>=0.27",
    "flash-attn==2.8.3",
    "liger-kernel>=0.5",
]

[project.scripts]
vggsound = "vggsound_pipeline.cli:app"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["src/vggsound_pipeline"]

[tool.uv]
environments = [
    "sys_platform == 'darwin' and platform_machine == 'arm64'",
    "sys_platform == 'linux'",
]
conflicts = [
    [{ extra = "cpu" }, { extra = "cuda" }],
    [{ extra = "cpu" }, { extra = "cuda-fast" }],
    [{ extra = "cuda" }, { extra = "cuda-fast" }],
]

[tool.uv.extra-build-dependencies]
flash-attn = ["torch"]
liger-kernel = ["torch"]

[tool.uv.sources]
torch = [
    { index = "pytorch-cpu", marker = "sys_platform == 'linux'", extra = "cpu" },
    { index = "pytorch-cu126", marker = "sys_platform == 'linux'", extra = "cuda" },
    { index = "pytorch-cu126", marker = "sys_platform == 'linux'", extra = "cuda-fast" },
]
torchaudio = [
    { index = "pytorch-cpu", marker = "sys_platform == 'linux'", extra = "cpu" },
    { index = "pytorch-cu126", marker = "sys_platform == 'linux'", extra = "cuda" },
    { index = "pytorch-cu126", marker = "sys_platform == 'linux'", extra = "cuda-fast" },
]
flash-attn = { url = "https://github.com/Dao-AILab/flash-attention/releases/download/v2.8.3/flash_attn-2.8.3+cu12torch2.9cxx11abiTRUE-cp312-cp312-linux_x86_64.whl" }

[[tool.uv.index]]
name = "pytorch-cpu"
url = "https://download.pytorch.org/whl/cpu"
explicit = true

[[tool.uv.index]]
name = "pytorch-cu126"
url = "https://download.pytorch.org/whl/cu126"
explicit = true

[tool.ruff]
line-length = 100

[tool.ruff.lint]
select = ["E", "F", "I", "UP"]

[tool.pytest.ini_options]
testpaths = ["tests"]
